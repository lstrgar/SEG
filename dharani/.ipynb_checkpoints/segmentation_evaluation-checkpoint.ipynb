{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea374b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import yaml\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "from skimage.measure import regionprops, label\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9845a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getid(samp_path):\n",
    "    return samp_path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5890b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pmask(segpath, r):\n",
    "    seg = imread(segpath)\n",
    "    mask = np.zeros_like(seg)\n",
    "    rps = regionprops(seg)\n",
    "    centroids = np.array(\n",
    "        list(map(lambda x : np.array(x.centroid).astype(int), rps))\n",
    "    )\n",
    "    mask[centroids[:,0], centroids[:,1]] = 1\n",
    "    mask = binary_dilation(mask, disk(r))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc420b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_masks(sid, radii, methods, datapath):\n",
    "    masks = {}\n",
    "    for r in radii:\n",
    "        rmasks = {}\n",
    "        for m in methods:\n",
    "            segpath = glob(os.path.join(datapath, m, sid + \"*\"))[0]\n",
    "            pmask = create_pmask(segpath, r)\n",
    "            rmasks[m] = pmask\n",
    "        stack = np.stack(list(rmasks.values()))\n",
    "        avg_mask = stack.mean(0)\n",
    "        rmasks[\"mean\"] = avg_mask\n",
    "        masks[r] = rmasks\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2220dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pmasks(sample_ids, radii, methods, datapath, save_dir):\n",
    "    print(f\"Writing probability masks for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        save_path = os.path.join(save_dir, f\"{sid}.pkl\")\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        sid_masks = compute_masks(sid, radii, methods, datapath)\n",
    "        with open(save_path, \"wb\") as handle:\n",
    "            pickle.dump(sid_masks, handle)\n",
    "    print(f\"Proability masks saved to {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f00419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(mask, avg_labs):\n",
    "    filtered = copy.deepcopy(mask)\n",
    "    mask_lab = label(mask)\n",
    "    rps = regionprops(mask_lab)\n",
    "    for rp in rps:\n",
    "        coords = rp.coords\n",
    "        vals = avg_labs[coords[:,0], coords[:,1]]\n",
    "        uniq, counts = np.unique(vals, return_counts=True)\n",
    "        if uniq[0] == 0:\n",
    "            uniq = uniq[1:]\n",
    "            counts = counts[1:]\n",
    "        n_unique = len(uniq)\n",
    "        if n_unique > 1:\n",
    "            amax = np.argmax(counts)\n",
    "            top_val = uniq[amax]\n",
    "            idxs = np.where(vals != top_val)\n",
    "            to_zero = coords[idxs,:][0]\n",
    "            filtered[to_zero[:,0], to_zero[:,1]] = False\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f721fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pmasks(sample_ids, pmask_save_dir, filtered_save_dir, min_num_agree, methods):\n",
    "    print(f\"Filtering probability masks for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        with open(os.path.join(pmask_save_dir, f\"{sid}.pkl\"), \"rb\") as handle:\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        filtered_masks = {}\n",
    "        for r, masks in data.items():\n",
    "            avg = masks[\"mean\"]\n",
    "            avg_threshd = (avg >= (min_num_agree / len(methods)))\n",
    "            avg_labs = label(avg_threshd)\n",
    "\n",
    "            r_filtered_masks = {}\n",
    "            for m in methods:\n",
    "                r_filtered_masks[m] = filter_mask(masks[m], avg_labs)\n",
    "\n",
    "            new_stack = np.stack(list(r_filtered_masks.values()))        \n",
    "            new_avg = new_stack.mean(0)\n",
    "            r_filtered_masks[\"mean\"] = new_avg\n",
    "            filtered_masks[r] = r_filtered_masks\n",
    "            \n",
    "        with open(os.path.join(filtered_save_dir, f\"{sid}.pkl\"), \"wb\") as handle:\n",
    "            pickle.dump(filtered_masks, handle)\n",
    "            \n",
    "    print(f\"Filtered probability masks saved to {filtered_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc3c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mask(gt, m):\n",
    "    rps = regionprops(m)\n",
    "    coords = list(map(lambda x : x.coords, rps))\n",
    "    correct = 0\n",
    "    \n",
    "    for c in coords:\n",
    "        correct += (gt[c[:,0], c[:,1]]).max()\n",
    "    precision = correct / len(rps)\n",
    "    \n",
    "    gt_labs = label(gt)\n",
    "    #print(gt_labs)\n",
    "    gt_rps = regionprops(gt_labs)\n",
    "    #print(gt_rps)\n",
    "    coords = list(map(lambda x : x.coords, gt_rps))\n",
    "    correct = 0\n",
    "    \n",
    "    for c in coords:\n",
    "        correct += (m[c[:,0], c[:,1]]).max() > 0\n",
    "    recall = correct / len(gt_rps)\n",
    "    \n",
    "    assert precision <= 1\n",
    "    assert precision >= 0\n",
    "    assert recall <= 1\n",
    "    assert recall >= 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55fd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_masks(sample_ids, filtered_pmask_save_dir, radii, min_num_agree, num_methods):\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    print(f\"Computing precision and recall for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        data_load_path = os.path.join(filtered_pmask_save_dir, f\"{sid}.pkl\")\n",
    "        with open(data_load_path, \"rb\") as handle:\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        sid_precisions = dict((r, {}) for r in radii)\n",
    "        sid_recalls = dict((r, {}) for r in radii)\n",
    "\n",
    "        for r, masks in data.items():\n",
    "\n",
    "            avg = masks[\"mean\"]\n",
    "            avg_thresh = (avg >= (min_num_agree / num_methods))\n",
    "            \n",
    "            for name, mask in masks.items():\n",
    "                if name == \"mean\":\n",
    "                    continue\n",
    "                labd_mask = label(mask)\n",
    "                prec, rec = eval_mask(avg_thresh, labd_mask)\n",
    "                sid_precisions[r][name] = prec\n",
    "                sid_recalls[r][name] = rec\n",
    "\n",
    "        precision[sid] = sid_precisions\n",
    "        recall[sid] = sid_recalls\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing probability masks for 88 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [2:32:45<00:00, 104.15s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proability masks saved to /home/groups/ChangLab/dharani/HMS-TMA-TNP_results_msur/pmasks\n",
      "Filtering probability masks for 88 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [46:29<00:00, 31.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered probability masks saved to /home/groups/ChangLab/dharani/HMS-TMA-TNP_results_msur/filtered_pmasks\n",
      "Computing precision and recall for 88 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 34/88 [09:09<15:00, 16.67s/it]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #parser = ArgumentParser()\n",
    "    #parser.add_argument(\"--config\", type=str, default=\"./config.yml\", help=\"Path to config file\")\n",
    "    #parser.add_argument(\"--compute-pmasks\", action=\"store_true\", help=\"Compute probability masks\")\n",
    "    #parser.add_argument(\"--filter-pmasks\", action=\"store_true\", help=\"Filter probability masks\")\n",
    "    #parser.add_argument(\"--compute-scores\", action=\"store_true\", help=\"Compute scores\")\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    # m - mesmer, s- startdist, c - cellpose, u-unet, r - MaskRCNN\n",
    "\n",
    "    #with open(args.config, \"r\") as handle:\n",
    "    #    config = yaml.load(handle, Loader=yaml.FullLoader)\n",
    "    methods =  [\"mesmer\", \"stardist\", \"maskrcnn\", \"unet\"] #config[\"methods\"]\n",
    "    radii = [2, 4, 6, 8, 10, 12, 14, 16] #config[\"radii\"]\n",
    "    num_agree = 3 #config[\"num_agree\"]\n",
    "    datapath = \"/home/groups/ChangLab/dataset/HMS-TMA-TNP/DATA-03292022\" #config[\"datapath\"]\n",
    "    results_dir = \"/home/groups/ChangLab/dharani/HMS-TMA-TNP_results_msur\" #config[\"resultsdir\"]\n",
    "    \n",
    "    compute_pmasks = True\n",
    "    filter_pmask = True\n",
    "    compute_scores = True\n",
    "\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    pmask_save_dir = os.path.join(results_dir, \"pmasks\")\n",
    "    if not os.path.exists(pmask_save_dir):\n",
    "        os.makedirs(pmask_save_dir)\n",
    "\n",
    "    sample_ids = os.listdir(os.path.join(datapath, methods[0]))\n",
    "    sample_ids = [s.split(\".\")[0] for s in sample_ids]\n",
    "    #sample_ids = sample_ids[0:20]\n",
    "\n",
    "    if compute_pmasks:\n",
    "        write_pmasks(sample_ids, radii, methods, datapath, pmask_save_dir)\n",
    "\n",
    "    filtered_pmask_save_dir = os.path.join(results_dir, \"filtered_pmasks\")\n",
    "    if not os.path.exists(filtered_pmask_save_dir):\n",
    "        os.makedirs(filtered_pmask_save_dir)\n",
    "\n",
    "    if filter_pmask:\n",
    "        filter_pmasks(sample_ids, pmask_save_dir, filtered_pmask_save_dir, num_agree, methods)\n",
    "\n",
    "    precision_scores_path = os.path.join(results_dir, \"precision_scores.pkl\")\n",
    "    recall_scores_path = os.path.join(results_dir, \"recall_scores.pkl\")\n",
    "\n",
    "    if compute_scores:\n",
    "        precision, recall = evaluate_masks(sample_ids, filtered_pmask_save_dir, radii, num_agree, len(methods))\n",
    "        with open(precision_scores_path, \"wb\") as handle:\n",
    "            pickle.dump(precision, handle)\n",
    "            print(f\"Saved precision scores to {precision_scores_path}\")\n",
    "        with open(recall_scores_path, \"wb\") as handle:\n",
    "            pickle.dump(recall, handle)\n",
    "            print(f\"Saved recall scores to {recall_scores_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f627ea61",
   "metadata": {},
   "source": [
    "### Code understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "object1 = pd.read_pickle(\"/home/groups/ChangLab/dharani/HMS-TMA-TNP_results_all5/filtered_pmasks/OHSU_TMA1_004-A1.pkl\")\n",
    "#object2 = pd.read_pickle(\"/home/groups/ChangLab/dataset/HMS-TMA-TNP/DATA-03292022/results/filtered_pmasks/OHSU_TMA1_004-A1.pkl\")\n",
    "#object3 = pd.read_pickle(\"/home/groups/ChangLab/dataset/HMS-TMA-TNP/DATA-03292022/results/precision_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b745185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(object1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e837aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, masks in object1.items():\n",
    "    #print(masks)\n",
    "    for i, j in masks.items():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/groups/ChangLab/dataset/HMS-TMA-TNP/DATA-03292022/results/pmasks/OHSU_TMA1_004-A1.pkl\", \"rb\") as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "#print(data)\n",
    "\n",
    "for r, masks in data.items():\n",
    "    filtered = copy.deepcopy(masks['cellpose'])\n",
    "    avg = masks[\"mean\"]\n",
    "    avg_threshd = (avg >= (3 / 5))\n",
    "    avg_labs = label(avg_threshd)\n",
    "    print(np.shape(avg_labs)) \n",
    "    #print(masks['cellpose'])\n",
    "    #print(label(masks['cellpose']))\n",
    "    mask_lab = label(masks['cellpose'])\n",
    "    rps = regionprops(mask_lab)\n",
    "    #print('rps', rps)\n",
    "    for rp in rps:\n",
    "        #print('rp', rp)\n",
    "        coords = rp.coords\n",
    "        #print('coords', coords)\n",
    "        vals = avg_labs[coords[:,0], coords[:,1]]\n",
    "        #print('Vals', vals)\n",
    "        uniq, counts = np.unique(vals, return_counts=True)\n",
    "        \n",
    "        amax = np.argmax(counts)\n",
    "        #print(amax)\n",
    "        top_val = uniq[amax]\n",
    "        #print(top_val)\n",
    "\n",
    "        idxs = np.where(vals != top_val)\n",
    "        #print(idxs)\n",
    "    \n",
    "        to_zero = coords[idxs,:][0]\n",
    "        #print(to_zero)\n",
    "\n",
    "        filtered[to_zero[:,0], to_zero[:,1]] = False\n",
    "        #print(filtered)\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "'''\n",
    "def filter_mask(mask, avg_labs):\n",
    "    filtered = copy.deepcopy(mask)\n",
    "    mask_lab = label(mask)\n",
    "    rps = regionprops(mask_lab)\n",
    "    for rp in rps:\n",
    "        coords = rp.coords\n",
    "        vals = avg_labs[coords[:,0], coords[:,1]]\n",
    "        uniq, counts = np.unique(vals, return_counts=True)\n",
    "        if uniq[0] == 0:\n",
    "            uniq = uniq[1:]\n",
    "            counts = counts[1:]\n",
    "        n_unique = len(uniq)\n",
    "        if n_unique > 1:\n",
    "            amax = np.argmax(counts)\n",
    "            top_val = uniq[amax]\n",
    "            idxs = np.where(vals != top_val)\n",
    "            to_zero = coords[idxs,:][0]\n",
    "            filtered[to_zero[:,0], to_zero[:,1]] = False\n",
    "    return filtered\n",
    "    \n",
    "    \n",
    "filtered_masks = {}\n",
    "for r, masks in data.items():\n",
    "    avg = masks[\"mean\"]\n",
    "    avg_threshd = (avg >= (min_num_agree / len(methods)))\n",
    "    avg_labs = label(avg_threshd)\n",
    "\n",
    "    r_filtered_masks = {}\n",
    "    for m in methods:\n",
    "        r_filtered_masks[m] = filter_mask(masks[m], avg_labs)\n",
    "\n",
    "    new_stack = np.stack(list(r_filtered_masks.values()))        \n",
    "    new_avg = new_stack.mean(0)\n",
    "    r_filtered_masks[\"mean\"] = new_avg\n",
    "    filtered_masks[r] = r_filtered_masks\n",
    "            \n",
    "#with open(os.path.join(filtered_save_dir, f\"{sid}.pkl\"), \"wb\") as handle:\n",
    "#    pickle.dump(filtered_masks, handle)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(a >= 5/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674291c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a >= 5/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0db2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "uniq, counts = np.unique(vals, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea681aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uniq, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae33397",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9aaa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "norm",
   "language": "python",
   "name": "norm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
