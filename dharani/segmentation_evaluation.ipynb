{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea374b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import yaml\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import binary_dilation, disk\n",
    "from skimage.measure import regionprops, label\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9845a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getid(samp_path):\n",
    "    return samp_path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pmask(segpath, r):\n",
    "    #print(\"create pmask\", segpath)\n",
    "    seg = imread(segpath)\n",
    "    mask = np.zeros_like(seg)\n",
    "    rps = regionprops(seg)\n",
    "    centroids = np.array(\n",
    "        list(map(lambda x : np.array(x.centroid).astype(int), rps))\n",
    "    )\n",
    "    mask[centroids[:,0], centroids[:,1]] = 1\n",
    "    mask = binary_dilation(mask, disk(r))\n",
    "    print(\"mask created\")\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc420b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_masks(sid, radii, methods, datapath):\n",
    "    masks = {}\n",
    "    for r in radii:\n",
    "        rmasks = {}\n",
    "        print('Radius', r)\n",
    "        for m in methods:\n",
    "            print(\"methods\", m)\n",
    "            #print(glob(os.path.join(datapath, m, sid + \"*\")))\n",
    "            segpath = glob(os.path.join(datapath, m, sid + \"*\"))[0]\n",
    "            #print(\"compute pmask\", segpath)\n",
    "            pmask = create_pmask(segpath, r)\n",
    "            rmasks[m] = pmask\n",
    "        stack = np.stack(list(rmasks.values()))\n",
    "        avg_mask = stack.mean(0)\n",
    "        rmasks[\"mean\"] = avg_mask\n",
    "        masks[r] = rmasks\n",
    "        print(\"Masks stacked\")\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pmasks(sample_ids, radii, methods, datapath, save_dir):\n",
    "    print(f\"Writing probability masks for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        save_path = os.path.join(save_dir, f\"{sid}.pkl\")\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "            \n",
    "        #print(\"sid\", sid)\n",
    "\n",
    "        sid_masks = compute_masks(sid, radii, methods, datapath)\n",
    "        with open(save_path, \"wb\") as handle:\n",
    "            pickle.dump(sid_masks, handle)\n",
    "    print(f\"Proability masks saved to {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f00419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(mask, avg_labs):\n",
    "    filtered = copy.deepcopy(mask)\n",
    "    mask_lab = label(mask)\n",
    "    rps = regionprops(mask_lab)\n",
    "    for rp in rps:\n",
    "        coords = rp.coords\n",
    "        vals = avg_labs[coords[:,0], coords[:,1]]\n",
    "        uniq, counts = np.unique(vals, return_counts=True)\n",
    "        if uniq[0] == 0:\n",
    "            uniq = uniq[1:]\n",
    "            counts = counts[1:]\n",
    "        n_unique = len(uniq)\n",
    "        if n_unique > 1:\n",
    "            amax = np.argmax(counts)\n",
    "            top_val = uniq[amax]\n",
    "            idxs = np.where(vals != top_val)\n",
    "            to_zero = coords[idxs,:][0]\n",
    "            filtered[to_zero[:,0], to_zero[:,1]] = False\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pmasks(sample_ids, pmask_save_dir, filtered_save_dir, min_num_agree, methods):\n",
    "    print(f\"Filtering probability masks for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        with open(os.path.join(pmask_save_dir, f\"{sid}.pkl\"), \"rb\") as handle:\n",
    "            print(os.path.join(pmask_save_dir, f\"{sid}.pkl\"))\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        filtered_masks = {}\n",
    "        for r, masks in data.items():\n",
    "            avg = masks[\"mean\"]\n",
    "            avg_threshd = (avg >= (min_num_agree / len(methods)))\n",
    "            avg_labs = label(avg_threshd)\n",
    "\n",
    "            r_filtered_masks = {}\n",
    "            for m in methods:\n",
    "                r_filtered_masks[m] = filter_mask(masks[m], avg_labs)\n",
    "\n",
    "            new_stack = np.stack(list(r_filtered_masks.values()))        \n",
    "            new_avg = new_stack.mean(0)\n",
    "            r_filtered_masks[\"mean\"] = new_avg\n",
    "            filtered_masks[r] = r_filtered_masks\n",
    "            \n",
    "        with open(os.path.join(filtered_save_dir, f\"{sid}.pkl\"), \"wb\") as handle:\n",
    "            pickle.dump(filtered_masks, handle)\n",
    "            \n",
    "    print(f\"Filtered probability masks saved to {filtered_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mask(gt, m):\n",
    "    rps = regionprops(m)\n",
    "    coords = list(map(lambda x : x.coords, rps))\n",
    "    correct = 0\n",
    "    \n",
    "    for c in coords:\n",
    "        correct += (gt[c[:,0], c[:,1]]).max()\n",
    "    precision = correct / len(rps)\n",
    "    \n",
    "    gt_labs = label(gt)\n",
    "    #print(gt_labs)\n",
    "    gt_rps = regionprops(gt_labs)\n",
    "    #print(gt_rps)\n",
    "    coords = list(map(lambda x : x.coords, gt_rps))\n",
    "    correct = 0\n",
    "    \n",
    "    for c in coords:\n",
    "        correct += (m[c[:,0], c[:,1]]).max() > 0\n",
    "    recall = correct / len(gt_rps)\n",
    "    \n",
    "    assert precision <= 1\n",
    "    assert precision >= 0\n",
    "    assert recall <= 1\n",
    "    assert recall >= 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_masks(sample_ids, filtered_pmask_save_dir, radii, min_num_agree, num_methods):\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    print(f\"Computing precision and recall for {len(sample_ids)} samples\")\n",
    "    for sid in tqdm(sample_ids):\n",
    "        data_load_path = os.path.join(filtered_pmask_save_dir, f\"{sid}.pkl\")\n",
    "        with open(data_load_path, \"rb\") as handle:\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        sid_precisions = dict((r, {}) for r in radii)\n",
    "        sid_recalls = dict((r, {}) for r in radii)\n",
    "\n",
    "        for r, masks in data.items():\n",
    "\n",
    "            avg = masks[\"mean\"]\n",
    "            avg_thresh = (avg >= (min_num_agree / num_methods))\n",
    "            \n",
    "            for name, mask in masks.items():\n",
    "                if name == \"mean\":\n",
    "                    continue\n",
    "                labd_mask = label(mask)\n",
    "                prec, rec = eval_mask(avg_thresh, labd_mask)\n",
    "                sid_precisions[r][name] = prec\n",
    "                sid_recalls[r][name] = rec\n",
    "\n",
    "        precision[sid] = sid_precisions\n",
    "        recall[sid] = sid_recalls\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #parser = ArgumentParser()\n",
    "    #parser.add_argument(\"--config\", type=str, default=\"./config.yml\", help=\"Path to config file\")\n",
    "    #parser.add_argument(\"--compute-pmasks\", action=\"store_true\", help=\"Compute probability masks\")\n",
    "    #parser.add_argument(\"--filter-pmasks\", action=\"store_true\", help=\"Filter probability masks\")\n",
    "    #parser.add_argument(\"--compute-scores\", action=\"store_true\", help=\"Compute scores\")\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    # m - mesmer, s- startdist, c - cellpose, u - unet, r - MaskRCNN, x - UnMicst\n",
    "\n",
    "    #with open(args.config, \"r\") as handle:\n",
    "    #    config = yaml.load(handle, Loader=yaml.FullLoader)\n",
    "    methods =  [\"Mesmer\", \"Stardist\", \"Cellpose\", \"UnMicst\"] #config[\"methods\"]\n",
    "    radii = [4, 8, 12, 16, 20, 24, 28, 32] #config[\"radii\"]\n",
    "    num_agree = 3 #config[\"num_agree\"]\n",
    "    datapath = \"/home/groups/ChangLab/dharani/OHSU-TMA/Segmentations\" #\"/home/groups/ChangLab/dataset/HMS-TMA-TNP/DATA-03292022\" # #config[\"datapath\"]\n",
    "    results_dir = \"/home/groups/ChangLab/dharani/OHSU-TMA/results_mscx\" #config[\"resultsdir\"]\n",
    "    \n",
    "    compute_pmasks = False\n",
    "    filter_pmask = True\n",
    "    compute_scores = True\n",
    "\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    pmask_save_dir = os.path.join(results_dir, \"pmasks\")\n",
    "    if not os.path.exists(pmask_save_dir):\n",
    "        os.makedirs(pmask_save_dir)\n",
    "\n",
    "    sample_ids = sorted(os.listdir(os.path.join(datapath, methods[0])))\n",
    "    sample_ids = [s.split(\".\")[0] for s in sample_ids]\n",
    "    #sample_ids = [s.split(\"_\")[0] for s in sample_ids] # only for the groundtruth\n",
    "    sample_ids = sample_ids[0:1]\n",
    "    print(\"sample_ids\", sample_ids)\n",
    "    \n",
    "\n",
    "    if compute_pmasks:\n",
    "        write_pmasks(sample_ids, radii, methods, datapath, pmask_save_dir)\n",
    "\n",
    "    filtered_pmask_save_dir = os.path.join(results_dir, \"filtered_pmasks\")\n",
    "    if not os.path.exists(filtered_pmask_save_dir):\n",
    "        os.makedirs(filtered_pmask_save_dir)\n",
    "\n",
    "    if filter_pmask:\n",
    "        filter_pmasks(sample_ids, pmask_save_dir, filtered_pmask_save_dir, num_agree, methods)\n",
    "\n",
    "    precision_scores_path = os.path.join(results_dir, \"precision_scores.pkl\")\n",
    "    recall_scores_path = os.path.join(results_dir, \"recall_scores.pkl\")\n",
    "\n",
    "    if compute_scores:\n",
    "        precision, recall = evaluate_masks(sample_ids, filtered_pmask_save_dir, radii, num_agree, len(methods))\n",
    "        with open(precision_scores_path, \"wb\") as handle:\n",
    "            pickle.dump(precision, handle)\n",
    "            print(f\"Saved precision scores to {precision_scores_path}\")\n",
    "        with open(recall_scores_path, \"wb\") as handle:\n",
    "            pickle.dump(recall, handle)\n",
    "            print(f\"Saved recall scores to {recall_scores_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76622f2",
   "metadata": {},
   "source": [
    "### Adjusted Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38e62d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.2120</td>\n",
       "      <td>-0.3170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.6420</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.1070</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.5610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.2290</td>\n",
       "      <td>0.4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.2826</td>\n",
       "      <td>-0.0484</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.3052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1      2      3       4       5\n",
       "0 -0.2120 -0.3170  0.000  0.317  0.3170     NaN\n",
       "1 -0.6420  0.0000  0.107  0.107     NaN  0.7490\n",
       "2 -0.1070  0.4280 -0.535    NaN  0.2140  0.2140\n",
       "3  0.1090  0.2180    NaN -0.546  0.0000  0.2180\n",
       "4 -0.5610     NaN  0.224  0.448  0.0000 -0.1120\n",
       "5     NaN -0.5710  0.229  0.114 -0.2290  0.4570\n",
       "6 -0.2826 -0.0484  0.005  0.088  0.0604  0.3052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# done - radius 2, 4, 6, 8, 10, 12, 14\n",
    "overall_scores = {0.945:[0.943, 0.942, 0.945, 0.948, 0.948, 0], # these values are from evaluation_quantification excel sheet\n",
    "                  0.935:[0.929, 0.935, 0.936, 0.936, 0, 0.942],\n",
    "                  0.934:[0.933, 0.938, 0.929, 0, 0.936, 0.936],\n",
    "                  0.916:[0.917, 0.918, 0, 0.911, 0.916, 0.918],\n",
    "                  0.892:[0.887, 0, 0.894, 0.896, 0.892, 0.891],\n",
    "                  0.875:[0, 0.870, 0.877, 0.876, 0.873, 0.879]}\n",
    "\n",
    "value_change = []\n",
    "\n",
    "for key, value in overall_scores.items():\n",
    "    temp = []\n",
    "    for i in value:\n",
    "        #print(key)\n",
    "        temp.append( ((i-key)/key)*100 )\n",
    "    value_change.append(temp)\n",
    "    \n",
    "df = pd.DataFrame(value_change)\n",
    "df = df.replace(-100.000000, np.NaN)\n",
    "df = df.round(3)\n",
    "df.loc[len(df.index)] = df.mean(axis=0, skipna=True)\n",
    "df = df.round(4)\n",
    "display(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cac7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2826, -0.0484, 0.005, 0.088, 0.0604, 0.3052]\n",
      "[0.12113992 0.15310841 0.16150663 0.17548371 0.17070658 0.21805476]\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[-1].tolist()\n",
    "print(x) #overall\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "print(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = {\"Mesmer\":{4:0.45, 8:0.05, 12:0.40, 16:0.10}, \"Stardist\":{4:0.04, 8:0.59, 12:0.06, 16:0.31}}\n",
    "\n",
    "#for key, value in config.items():\n",
    "#    for radius, ratio in value.items():\n",
    "#        if key == \"Stardist\" and radius == 4:\n",
    "#            print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 : [0.15708386 0.16780117 0.15878956 0.16786831 0.17760816 0.17084894]\n",
    "4 : [0.15110248 0.15107227 0.14010026 0.18481555 0.21399621 0.15891323]\n",
    "6 : [0.08883816 0.09650707 0.15456524 0.12052007 0.29032945 0.24924]\n",
    "8 : [0.09821838 0.08273092 0.13536751 0.20905416 0.20934704 0.26528199]\n",
    "10 : [0.13989789 0.11099807 0.16678621 0.18547365 0.14482307 0.2520211 ]\n",
    "12 : [0.1258211  0.12931626 0.16634452 0.18505647 0.14180616 0.25165549]\n",
    "14 : [0.12531543 0.14245611 0.17150869 0.16851655 0.1434568  0.24874642]\n",
    "16 : [0.12113992 0.15310841 0.16150663 0.17548371 0.17070658 0.21805476]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53d0e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_array = [[0.15708386, 0.16780117, 0.15878956, 0.16786831, 0.17760816, 0.17084894],\n",
    "                 [0.15110248, 0.15107227, 0.14010026, 0.18481555, 0.21399621, 0.15891323],\n",
    "                 [0.08883816, 0.09650707, 0.15456524, 0.12052007, 0.29032945, 0.24924],\n",
    "                 [0.09821838, 0.08273092, 0.13536751, 0.20905416, 0.20934704, 0.26528199],\n",
    "                 [0.13989789, 0.11099807, 0.16678621, 0.18547365, 0.14482307, 0.2520211 ],\n",
    "                 [0.1258211,  0.12931626, 0.16634452, 0.18505647, 0.14180616, 0.25165549],\n",
    "                 [0.12531543, 0.14245611, 0.17150869, 0.16851655, 0.1434568,  0.24874642],\n",
    "                 [0.12113992, 0.15310841, 0.16150663, 0.17548371, 0.17070658, 0.21805476]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "042af0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_array_transpose = np.transpose(weights_array)\n",
    "\n",
    "radius = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "methods = [\"unmicst\", \"unet\", \"cellpose\", \"maskrcnn\", \"stardist\", \"mesmer\"]\n",
    "weights_dict = {}\n",
    "\n",
    "weights_df = pd.DataFrame(weights_array_transpose)\n",
    "#display(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cce157cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    temp_list = weights_df.iloc[i].tolist()\n",
    "    temp_dict = {}\n",
    "    for j in range(len(temp_list)):\n",
    "        temp_dict[radius[j]] = temp_list[j]\n",
    "    weights_dict[methods[i]] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65b7f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unmicst': {2: 0.15708386,\n",
       "  4: 0.15110248,\n",
       "  6: 0.08883816,\n",
       "  8: 0.09821838,\n",
       "  10: 0.13989789,\n",
       "  12: 0.1258211,\n",
       "  14: 0.12531543,\n",
       "  16: 0.12113992},\n",
       " 'unet': {2: 0.16780117,\n",
       "  4: 0.15107227,\n",
       "  6: 0.09650707,\n",
       "  8: 0.08273092,\n",
       "  10: 0.11099807,\n",
       "  12: 0.12931626,\n",
       "  14: 0.14245611,\n",
       "  16: 0.15310841},\n",
       " 'cellpose': {2: 0.15878956,\n",
       "  4: 0.14010026,\n",
       "  6: 0.15456524,\n",
       "  8: 0.13536751,\n",
       "  10: 0.16678621,\n",
       "  12: 0.16634452,\n",
       "  14: 0.17150869,\n",
       "  16: 0.16150663},\n",
       " 'maskrcnn': {2: 0.16786831,\n",
       "  4: 0.18481555,\n",
       "  6: 0.12052007,\n",
       "  8: 0.20905416,\n",
       "  10: 0.18547365,\n",
       "  12: 0.18505647,\n",
       "  14: 0.16851655,\n",
       "  16: 0.17548371},\n",
       " 'stardist': {2: 0.17760816,\n",
       "  4: 0.21399621,\n",
       "  6: 0.29032945,\n",
       "  8: 0.20934704,\n",
       "  10: 0.14482307,\n",
       "  12: 0.14180616,\n",
       "  14: 0.1434568,\n",
       "  16: 0.17070658},\n",
       " 'mesmer': {2: 0.17084894,\n",
       "  4: 0.15891323,\n",
       "  6: 0.24924,\n",
       "  8: 0.26528199,\n",
       "  10: 0.2520211,\n",
       "  12: 0.25165549,\n",
       "  14: 0.24874642,\n",
       "  16: 0.21805476}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc076e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "norm",
   "language": "python",
   "name": "norm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
